{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usage of noise / randomness in optimization problems is well known. Some examples includes simulated annealing,  genetic algorithms and actually my thesis. The issue of adding noise to the gradient in deep neural networks was addressed in an article called: \"Adding gradient noise improves learning for very deep networks\".\n",
    "\n",
    "The addition of noise should help by reducing overfitting, avoid local minima and more easily escape flat area in the loss surface.\n",
    "Having said that. Modern technics have the same properties (when talking about cnn-fc networks). SGD and its extensions is known to reduce overfitting and the incorporation of dropout and relu's also helps a lot.\n",
    "The net in the exercise is very similar to one of the nets the authors tested on the article for which the noise addition did not contribute to its performances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import inspect\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://github.com/cpury/keras_gradient_noise\n",
    "\n",
    "\n",
    "def add_gradient_noise(BaseOptimizer):\n",
    "    \"\"\"\n",
    "    Given a Keras-compatible optimizer class, returns a modified class that\n",
    "    supports adding gradient noise as introduced in this paper:\n",
    "    https://arxiv.org/abs/1511.06807\n",
    "    The relevant parameters from equation 1 in the paper can be set via\n",
    "    noise_eta and noise_gamma, set by default to 0.3 and 0.55 respectively.\n",
    "    \"\"\"\n",
    "    if not (\n",
    "        inspect.isclass(BaseOptimizer) and\n",
    "        issubclass(BaseOptimizer, keras.optimizers.Optimizer)\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            'add_gradient_noise() expects a valid Keras optimizer'\n",
    "        )\n",
    "\n",
    "    class NoisyOptimizer(BaseOptimizer):\n",
    "        def __init__(self, noise_eta=1, noise_gamma=0.5, **kwargs):\n",
    "            super(NoisyOptimizer, self).__init__(**kwargs)\n",
    "            with K.name_scope(self.__class__.__name__):\n",
    "                self.noise_eta = K.variable(noise_eta, name='noise_eta')\n",
    "                self.noise_gamma = K.variable(noise_gamma, name='noise_gamma')\n",
    "\n",
    "        def get_gradients(self, loss, params):\n",
    "            grads = super(NoisyOptimizer, self).get_gradients(loss, params)\n",
    "\n",
    "            # Add decayed gaussian noise\n",
    "            t = K.cast(self.iterations, K.dtype(grads[0]))\n",
    "            variance = self.noise_eta / ((1 + t) ** self.noise_gamma)\n",
    "            \n",
    "\n",
    "            grads = [\n",
    "                grad + K.random_normal(\n",
    "                    grad.shape,\n",
    "                    mean=0.0,\n",
    "                    stddev=K.sqrt(variance),\n",
    "                    dtype=K.dtype(grads[0])\n",
    "                )\n",
    "                for grad in grads\n",
    "            ]\n",
    "\n",
    "            return grads\n",
    "\n",
    "        def get_config(self):\n",
    "            config = {'noise_eta': float(K.get_value(self.noise_eta)),\n",
    "                      'noise_gamma': float(K.get_value(self.noise_gamma))}\n",
    "            base_config = super(NoisyOptimizer, self).get_config()\n",
    "            return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    NoisyOptimizer.__name__ = 'Noisy{}'.format(BaseOptimizer.__name__)\n",
    "\n",
    "    return NoisyOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_model(add_noise,dropout_p,input_shape,activation_func,initializer):\n",
    "    '''here we get the model per spec. The basic struc is the same but \n",
    "    we can play with noise addition, dropout'''\n",
    "    num_classes=10\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation=activation_func,kernel_initializer=initializer,\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activation_func,kernel_initializer=initializer))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(dropout_p[0]))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=activation_func,kernel_initializer=initializer))\n",
    "    model.add(Dropout(dropout_p[1]))\n",
    "    model.add(Dense(num_classes, activation='softmax',kernel_initializer=initializer))\n",
    "    if not add_noise:\n",
    "        optimizer_to_use=keras.optimizers.Adadelta()\n",
    "    else:\n",
    "        Noisy=add_gradient_noise(keras.optimizers.Adadelta)\n",
    "        #Noisy=add_gradient_noise(keras.optimizers.Adam)\n",
    "        Noisy=add_gradient_noise(keras.optimizers.SGD)\n",
    "\n",
    "        optimizer_to_use=Noisy()\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=optimizer_to_use,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_and_test(model,total_iteration,x_test,y_test,x_train,y_train,epoces_per_step,add_noise):\n",
    "    '''a simple func doing the train in loops so we can take a look of train and test results as we\n",
    "    train the net more and more. The final result is a dataframe with the run data'''\n",
    "    result_list=[]\n",
    "    for iteration in range(total_iteration):\n",
    "        temp_dict={}\n",
    "\n",
    "        model.fit(x_train, y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epoces_per_step,\n",
    "                      verbose=1,\n",
    "                      validation_data=(x_test, y_test))\n",
    "        score_train = model.evaluate(x_train, y_train, verbose=0)\n",
    "        score_test = model.evaluate(x_test, y_test, verbose=0)\n",
    "        temp_dict[\"epochs\"]=(iteration+1)*epoces_per_step\n",
    "        temp_dict[\"add_noise\"]=add_noise\n",
    "        temp_dict[\"train_loss\"]=score_train[0]\n",
    "        temp_dict[\"train_accuracy\"]=score_train[1]\n",
    "        temp_dict[\"test_loss\"]=score_test[0]\n",
    "        temp_dict[\"test_accuracy\"]=score_test[1]\n",
    "        result_list.append(temp_dict)\n",
    "        print(\"iteration {} out of {}\".format(iteration+1,total_iteration))\n",
    "    results_df=pd.DataFrame(result_list)\n",
    "    column_order_list=[\"epochs\",\"add_noise\",\"train_accuracy\",\"test_accuracy\",\"train_loss\",\"test_loss\"]\n",
    "    results_df=results_df[column_order_list]\n",
    "    return results_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(train_num=\"all\"):\n",
    "    '''taking care of importing and some (very limited) preproccessing'''\n",
    "    \n",
    "    img_rows=28\n",
    "    img_cols =28\n",
    "    num_classes=10\n",
    "\n",
    "    # the data, split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    if train_num!=\"all\":\n",
    "        x_train=x_train[:train_num]\n",
    "        y_train=y_train[:train_num]\n",
    "        \n",
    "    \n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    \n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    \n",
    "    a=np.unique(y_train, return_counts=True)\n",
    "    df=pd.DataFrame([])\n",
    "    df[\"lable\"]=a[0]\n",
    "    df[\"count\"]=a[1]\n",
    "    df.plot(\"lable\",\"count\",kind=\"bar\",title=\"train counts\",color=\"r\",legend=False)\n",
    "    a=np.unique(y_test, return_counts=True)\n",
    "    df=pd.DataFrame([])\n",
    "    df[\"lable\"]=a[0]\n",
    "    df[\"count\"]=a[1]\n",
    "    df.plot(\"lable\",\"count\",kind=\"bar\",title=\"test counts\",color=\"b\",legend=False)\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    return x_train, x_test, y_train,y_test,input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets train two networks. The original provided and a second where we add the noise to the gradient. We will use the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14858d550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x146d355f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_num=\"all\"\n",
    "x_train, x_test, y_train,y_test,input_shape=get_train_test(train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_noise=False\n",
    "dropout_p=[0.25,0.5] \n",
    "activation_func=\"relu\"\n",
    "initializer='glorot_uniform'#glorot_uniform is default. also try zeros\n",
    "batch_size=128\n",
    "epoces_per_step=3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "add_noise=False\n",
    "model_clean=get_model(add_noise,dropout_p,input_shape,activation_func,initializer)\n",
    "add_noise=True\n",
    "model_noise=get_model(add_noise,dropout_p,input_shape,activation_func,initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.3243 - acc: 0.9000 - val_loss: 0.0784 - val_acc: 0.9752\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.1120 - acc: 0.9669 - val_loss: 0.0572 - val_acc: 0.9825\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0862 - acc: 0.9739 - val_loss: 0.0448 - val_acc: 0.9852\n",
      "iteration 1 out of 5\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0715 - acc: 0.9785 - val_loss: 0.0381 - val_acc: 0.9876\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 113s 2ms/step - loss: 0.0637 - acc: 0.9809 - val_loss: 0.0339 - val_acc: 0.9884\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0574 - acc: 0.9833 - val_loss: 0.0310 - val_acc: 0.9889\n",
      "iteration 2 out of 5\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0499 - acc: 0.9850 - val_loss: 0.0296 - val_acc: 0.9906\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0486 - acc: 0.9855 - val_loss: 0.0293 - val_acc: 0.9898\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0445 - acc: 0.9867 - val_loss: 0.0284 - val_acc: 0.9901\n",
      "iteration 3 out of 5\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0423 - acc: 0.9871 - val_loss: 0.0281 - val_acc: 0.9897\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 110s 2ms/step - loss: 0.0377 - acc: 0.9886 - val_loss: 0.0278 - val_acc: 0.9910\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 110s 2ms/step - loss: 0.0373 - acc: 0.9890 - val_loss: 0.0266 - val_acc: 0.9911\n",
      "iteration 4 out of 5\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 110s 2ms/step - loss: 0.0371 - acc: 0.9891 - val_loss: 0.0267 - val_acc: 0.9909\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 110s 2ms/step - loss: 0.0348 - acc: 0.9892 - val_loss: 0.0289 - val_acc: 0.9904\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 110s 2ms/step - loss: 0.0330 - acc: 0.9902 - val_loss: 0.0261 - val_acc: 0.9915\n",
      "iteration 5 out of 5\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 115s 2ms/step - loss: 2.2340 - acc: 0.1756 - val_loss: 2.0696 - val_acc: 0.4981\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 1.6588 - acc: 0.5020 - val_loss: 0.8280 - val_acc: 0.8219\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 113s 2ms/step - loss: 0.8843 - acc: 0.7212 - val_loss: 0.4676 - val_acc: 0.8739\n",
      "iteration 1 out of 7\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 113s 2ms/step - loss: 0.6744 - acc: 0.7872 - val_loss: 0.3795 - val_acc: 0.8915\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 113s 2ms/step - loss: 0.5952 - acc: 0.8116 - val_loss: 0.3430 - val_acc: 0.8994\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.5469 - acc: 0.8294 - val_loss: 0.3072 - val_acc: 0.9126\n",
      "iteration 2 out of 7\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.5164 - acc: 0.8398 - val_loss: 0.2908 - val_acc: 0.9170\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 113s 2ms/step - loss: 0.4863 - acc: 0.8482 - val_loss: 0.2716 - val_acc: 0.9232\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.4720 - acc: 0.8534 - val_loss: 0.2611 - val_acc: 0.9252\n",
      "iteration 3 out of 7\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.4533 - acc: 0.8602 - val_loss: 0.2497 - val_acc: 0.9287\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.4462 - acc: 0.8613 - val_loss: 0.2402 - val_acc: 0.9311\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.4282 - acc: 0.8676 - val_loss: 0.2305 - val_acc: 0.9315\n",
      "iteration 4 out of 7\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.4239 - acc: 0.8686 - val_loss: 0.2242 - val_acc: 0.9350\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.4064 - acc: 0.8727 - val_loss: 0.2208 - val_acc: 0.9354\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.4035 - acc: 0.8749 - val_loss: 0.2132 - val_acc: 0.9390\n",
      "iteration 5 out of 7\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.3960 - acc: 0.8775 - val_loss: 0.2059 - val_acc: 0.9392\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 113s 2ms/step - loss: 0.3908 - acc: 0.8787 - val_loss: 0.2047 - val_acc: 0.9407\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 113s 2ms/step - loss: 0.3819 - acc: 0.8811 - val_loss: 0.1976 - val_acc: 0.9421\n",
      "iteration 6 out of 7\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 113s 2ms/step - loss: 0.3777 - acc: 0.8838 - val_loss: 0.1954 - val_acc: 0.9431\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 0.3684 - acc: 0.8850 - val_loss: 0.1865 - val_acc: 0.9458\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 113s 2ms/step - loss: 0.3632 - acc: 0.8886 - val_loss: 0.1857 - val_acc: 0.9459\n",
      "iteration 7 out of 7\n"
     ]
    }
   ],
   "source": [
    "total_iteration=5\n",
    "results_clean_df=train_and_test(model_clean,total_iteration,x_test,y_test,x_train,y_train,epoces_per_step,add_noise)\n",
    "total_iteration=7\n",
    "results_noise_df=train_and_test(model_noise,total_iteration,x_test,y_test,x_train,y_train,epoces_per_step,add_noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>add_noise</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.987450</td>\n",
       "      <td>0.9852</td>\n",
       "      <td>0.042484</td>\n",
       "      <td>0.044803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>0.992283</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.025985</td>\n",
       "      <td>0.031016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>0.993917</td>\n",
       "      <td>0.9901</td>\n",
       "      <td>0.019765</td>\n",
       "      <td>0.028393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>0.995417</td>\n",
       "      <td>0.9911</td>\n",
       "      <td>0.015845</td>\n",
       "      <td>0.026647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>0.996133</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>0.013438</td>\n",
       "      <td>0.026062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epochs  add_noise  train_accuracy  test_accuracy  train_loss  test_loss\n",
       "0       3       True        0.987450         0.9852    0.042484   0.044803\n",
       "1       6       True        0.992283         0.9889    0.025985   0.031016\n",
       "2       9       True        0.993917         0.9901    0.019765   0.028393\n",
       "3      12       True        0.995417         0.9911    0.015845   0.026647\n",
       "4      15       True        0.996133         0.9915    0.013438   0.026062"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results of original net\n",
    "results_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>add_noise</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.865700</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.489644</td>\n",
       "      <td>0.467638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>0.906517</td>\n",
       "      <td>0.9126</td>\n",
       "      <td>0.324232</td>\n",
       "      <td>0.307185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>0.922650</td>\n",
       "      <td>0.9252</td>\n",
       "      <td>0.273698</td>\n",
       "      <td>0.261085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>0.929417</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>0.243103</td>\n",
       "      <td>0.230492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>0.935233</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>0.223427</td>\n",
       "      <td>0.213230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>0.940233</td>\n",
       "      <td>0.9421</td>\n",
       "      <td>0.204773</td>\n",
       "      <td>0.197581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>0.943950</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.194029</td>\n",
       "      <td>0.185670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epochs  add_noise  train_accuracy  test_accuracy  train_loss  test_loss\n",
       "0       3       True        0.865700         0.8739    0.489644   0.467638\n",
       "1       6       True        0.906517         0.9126    0.324232   0.307185\n",
       "2       9       True        0.922650         0.9252    0.273698   0.261085\n",
       "3      12       True        0.929417         0.9315    0.243103   0.230492\n",
       "4      15       True        0.935233         0.9390    0.223427   0.213230\n",
       "5      18       True        0.940233         0.9421    0.204773   0.197581\n",
       "6      21       True        0.943950         0.9459    0.194029   0.185670"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#results of noisy net\n",
    "results_noise_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see thet noisy net learns slower and not as good as original net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets move from Adadelta to sgd when applying the noise. sgd does not carry with it history of gradient so should work better (this is also what they used in the article). To save time we will directly demonstrate on a vary bad initiation. All weights are set to zero so no training in regular methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_p=[0,0]\n",
    "activation_func=\"relu\"\n",
    "initializer='zeros'#glorot_uniform is default. also try zeros\n",
    "batch_size=128\n",
    "epoces_per_step=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_noise=True\n",
    "model_noise_sgd=get_model(add_noise,dropout_p,input_shape,activation_func,initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 106s 2ms/step - loss: 1.6821 - acc: 0.4327 - val_loss: 0.4231 - val_acc: 0.8795\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 104s 2ms/step - loss: 0.3648 - acc: 0.8896 - val_loss: 0.2932 - val_acc: 0.9165\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.2820 - acc: 0.9162 - val_loss: 0.2448 - val_acc: 0.9262\n",
      "iteration 1 out of 3\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.2441 - acc: 0.9284 - val_loss: 0.2248 - val_acc: 0.9288\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 104s 2ms/step - loss: 0.2204 - acc: 0.9345 - val_loss: 0.1905 - val_acc: 0.9425\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 104s 2ms/step - loss: 0.2018 - acc: 0.9400 - val_loss: 0.1872 - val_acc: 0.9429\n",
      "iteration 2 out of 3\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 104s 2ms/step - loss: 0.1869 - acc: 0.9436 - val_loss: 0.1776 - val_acc: 0.9452\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 104s 2ms/step - loss: 0.1727 - acc: 0.9480 - val_loss: 0.1617 - val_acc: 0.9510\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.1633 - acc: 0.9509 - val_loss: 0.1725 - val_acc: 0.9488\n",
      "iteration 3 out of 3\n"
     ]
    }
   ],
   "source": [
    "total_iteration=3\n",
    "results_noise_df_sgd_zeros=train_and_test(model_noise_sgd\\\n",
    "                                          ,total_iteration,x_test,y_test,x_train,y_train,epoces_per_step,add_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>add_noise</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.924033</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>0.252632</td>\n",
       "      <td>0.244843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>0.942017</td>\n",
       "      <td>0.9429</td>\n",
       "      <td>0.191667</td>\n",
       "      <td>0.187181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>0.949850</td>\n",
       "      <td>0.9488</td>\n",
       "      <td>0.163322</td>\n",
       "      <td>0.172472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epochs  add_noise  train_accuracy  test_accuracy  train_loss  test_loss\n",
       "0       3       True        0.924033         0.9262    0.252632   0.244843\n",
       "1       6       True        0.942017         0.9429    0.191667   0.187181\n",
       "2       9       True        0.949850         0.9488    0.163322   0.172472"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_noise_df_sgd_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that in spite the poor initialization, the net is capable to learn, much faster then perviously when used Adadelta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lets take a much smaller dataset, induce overfit and compare the two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (500, 28, 28, 1)\n",
      "500 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15744ffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15745b588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_num=500\n",
    "x_train, x_test, y_train,y_test,input_shape=get_train_test(train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_p=[0.25,0.5]\n",
    "activation_func=\"relu\"\n",
    "initializer='glorot_uniform'#glorot_uniform is default. also try zeros\n",
    "batch_size=128\n",
    "epoces_per_step=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_noise=False\n",
    "model_small_dataset=get_model(add_noise,dropout_p,input_shape,activation_func,initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 9s 17ms/step - loss: 2.2537 - acc: 0.2100 - val_loss: 2.1082 - val_acc: 0.4194\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 1.9629 - acc: 0.4620 - val_loss: 1.7315 - val_acc: 0.5189\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 1.5045 - acc: 0.5760 - val_loss: 1.3496 - val_acc: 0.6059\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 1.2722 - acc: 0.6320 - val_loss: 1.0532 - val_acc: 0.7118\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.9070 - acc: 0.7220 - val_loss: 1.0189 - val_acc: 0.6919\n",
      "iteration 1 out of 5\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.8096 - acc: 0.7820 - val_loss: 0.8656 - val_acc: 0.7328\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.5639 - acc: 0.8340 - val_loss: 0.7073 - val_acc: 0.7623\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.6523 - acc: 0.7980 - val_loss: 0.5821 - val_acc: 0.8296\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.4270 - acc: 0.8860 - val_loss: 0.5280 - val_acc: 0.8389\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.4538 - acc: 0.8540 - val_loss: 0.5136 - val_acc: 0.8450\n",
      "iteration 2 out of 5\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.3856 - acc: 0.8880 - val_loss: 0.5428 - val_acc: 0.8353\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.3784 - acc: 0.8980 - val_loss: 0.4956 - val_acc: 0.8488\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.3187 - acc: 0.9060 - val_loss: 0.5053 - val_acc: 0.8412\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.3473 - acc: 0.8940 - val_loss: 0.5141 - val_acc: 0.8403\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.2815 - acc: 0.9380 - val_loss: 0.5000 - val_acc: 0.8379\n",
      "iteration 3 out of 5\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2471 - acc: 0.9240 - val_loss: 0.4355 - val_acc: 0.8676\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2147 - acc: 0.9420 - val_loss: 0.4613 - val_acc: 0.8587\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2441 - acc: 0.9220 - val_loss: 0.5040 - val_acc: 0.8436\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1883 - acc: 0.9520 - val_loss: 0.4808 - val_acc: 0.8511\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1429 - acc: 0.9620 - val_loss: 0.4578 - val_acc: 0.8627\n",
      "iteration 4 out of 5\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1652 - acc: 0.9360 - val_loss: 0.4408 - val_acc: 0.8669\n",
      "Epoch 2/5\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.1315 - acc: 0.9540 - val_loss: 0.4918 - val_acc: 0.8526\n",
      "Epoch 3/5\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.1548 - acc: 0.9560 - val_loss: 0.4448 - val_acc: 0.8704\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1422 - acc: 0.9440 - val_loss: 0.5057 - val_acc: 0.8541\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.1380 - acc: 0.9660 - val_loss: 0.4166 - val_acc: 0.8794\n",
      "iteration 5 out of 5\n"
     ]
    }
   ],
   "source": [
    "total_iteration=5\n",
    "results_small_dataset=train_and_test(model_small_dataset\\\n",
    "                                          ,total_iteration,x_test,y_test,x_train,y_train,epoces_per_step,add_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>add_noise</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>0.674624</td>\n",
       "      <td>1.018910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.8450</td>\n",
       "      <td>0.255042</td>\n",
       "      <td>0.513588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.8379</td>\n",
       "      <td>0.156744</td>\n",
       "      <td>0.499964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.8627</td>\n",
       "      <td>0.084461</td>\n",
       "      <td>0.457826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.8794</td>\n",
       "      <td>0.048178</td>\n",
       "      <td>0.416570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epochs  add_noise  train_accuracy  test_accuracy  train_loss  test_loss\n",
       "0       5      False           0.810         0.6919    0.674624   1.018910\n",
       "1      10      False           0.926         0.8450    0.255042   0.513588\n",
       "2      15      False           0.938         0.8379    0.156744   0.499964\n",
       "3      20      False           0.986         0.8627    0.084461   0.457826\n",
       "4      25      False           0.994         0.8794    0.048178   0.416570"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_small_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sgd with noise, no dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_p=[0,0]\n",
    "activation_func=\"relu\"\n",
    "initializer='glorot_uniform'#glorot_uniform is default. also try zeros\n",
    "batch_size=128\n",
    "epoces_per_step=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_noise=True\n",
    "model_noise_sgd_small_dataset=get_model(add_noise,dropout_p,input_shape,activation_func,initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "500/500 [==============================] - 8s 17ms/step - loss: 2.3141 - acc: 0.0440 - val_loss: 2.2977 - val_acc: 0.0773\n",
      "Epoch 2/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.2856 - acc: 0.1400 - val_loss: 2.2935 - val_acc: 0.1044\n",
      "Epoch 3/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.2694 - acc: 0.1300 - val_loss: 2.2650 - val_acc: 0.1170\n",
      "Epoch 4/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 2.2462 - acc: 0.1620 - val_loss: 2.2463 - val_acc: 0.1997\n",
      "Epoch 5/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.2191 - acc: 0.2620 - val_loss: 2.2169 - val_acc: 0.2870\n",
      "Epoch 6/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.1844 - acc: 0.2760 - val_loss: 2.1845 - val_acc: 0.2221\n",
      "Epoch 7/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.1343 - acc: 0.3020 - val_loss: 2.1198 - val_acc: 0.3220\n",
      "Epoch 8/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.0655 - acc: 0.3580 - val_loss: 2.0583 - val_acc: 0.3847\n",
      "Epoch 9/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 2.0000 - acc: 0.4280 - val_loss: 2.0197 - val_acc: 0.3796\n",
      "Epoch 10/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 1.9441 - acc: 0.4900 - val_loss: 1.9709 - val_acc: 0.4291\n",
      "Epoch 11/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.8687 - acc: 0.5360 - val_loss: 1.8869 - val_acc: 0.4752\n",
      "Epoch 12/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 1.7516 - acc: 0.5780 - val_loss: 1.7836 - val_acc: 0.5246\n",
      "Epoch 13/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.6375 - acc: 0.6240 - val_loss: 1.6650 - val_acc: 0.5798\n",
      "Epoch 14/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.5122 - acc: 0.6620 - val_loss: 1.5852 - val_acc: 0.5745\n",
      "Epoch 15/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.4051 - acc: 0.6820 - val_loss: 1.4859 - val_acc: 0.5886\n",
      "iteration 1 out of 8\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.2887 - acc: 0.7140 - val_loss: 1.3557 - val_acc: 0.6294\n",
      "Epoch 2/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.1534 - acc: 0.7260 - val_loss: 1.2756 - val_acc: 0.6585\n",
      "Epoch 3/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 1.0659 - acc: 0.7640 - val_loss: 1.1568 - val_acc: 0.6942\n",
      "Epoch 4/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.9559 - acc: 0.7800 - val_loss: 1.0792 - val_acc: 0.6961\n",
      "Epoch 5/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.8544 - acc: 0.8100 - val_loss: 0.9999 - val_acc: 0.7310\n",
      "Epoch 6/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.7856 - acc: 0.8240 - val_loss: 0.9424 - val_acc: 0.7381\n",
      "Epoch 7/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.7354 - acc: 0.8300 - val_loss: 0.8815 - val_acc: 0.7487\n",
      "Epoch 8/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.6881 - acc: 0.8320 - val_loss: 0.8805 - val_acc: 0.7410\n",
      "Epoch 9/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.6643 - acc: 0.8320 - val_loss: 0.8292 - val_acc: 0.7505\n",
      "Epoch 10/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.6271 - acc: 0.8420 - val_loss: 0.8069 - val_acc: 0.7541\n",
      "Epoch 11/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.5795 - acc: 0.8460 - val_loss: 0.7633 - val_acc: 0.7618\n",
      "Epoch 12/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.5457 - acc: 0.8620 - val_loss: 0.7471 - val_acc: 0.7766\n",
      "Epoch 13/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.5222 - acc: 0.8640 - val_loss: 0.7106 - val_acc: 0.7809\n",
      "Epoch 14/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.5019 - acc: 0.8680 - val_loss: 0.6965 - val_acc: 0.7827\n",
      "Epoch 15/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.4683 - acc: 0.8660 - val_loss: 0.6768 - val_acc: 0.7900\n",
      "iteration 2 out of 8\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.4544 - acc: 0.8880 - val_loss: 0.6617 - val_acc: 0.7963\n",
      "Epoch 2/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.4305 - acc: 0.8940 - val_loss: 0.6404 - val_acc: 0.8050\n",
      "Epoch 3/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.4114 - acc: 0.8900 - val_loss: 0.6258 - val_acc: 0.8042\n",
      "Epoch 4/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.4004 - acc: 0.9020 - val_loss: 0.6279 - val_acc: 0.8055\n",
      "Epoch 5/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.3961 - acc: 0.8940 - val_loss: 0.6157 - val_acc: 0.8049\n",
      "Epoch 6/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.3814 - acc: 0.8980 - val_loss: 0.6303 - val_acc: 0.7993\n",
      "Epoch 7/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.3739 - acc: 0.9040 - val_loss: 0.6124 - val_acc: 0.8035\n",
      "Epoch 8/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.3633 - acc: 0.8980 - val_loss: 0.6070 - val_acc: 0.8070\n",
      "Epoch 9/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.3530 - acc: 0.8960 - val_loss: 0.5870 - val_acc: 0.8106\n",
      "Epoch 10/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.3445 - acc: 0.9080 - val_loss: 0.5927 - val_acc: 0.8072\n",
      "Epoch 11/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.3322 - acc: 0.9100 - val_loss: 0.5961 - val_acc: 0.8020\n",
      "Epoch 12/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.3273 - acc: 0.9080 - val_loss: 0.5748 - val_acc: 0.8110\n",
      "Epoch 13/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.3098 - acc: 0.9160 - val_loss: 0.5683 - val_acc: 0.8170\n",
      "Epoch 14/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2979 - acc: 0.9140 - val_loss: 0.5818 - val_acc: 0.8119\n",
      "Epoch 15/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.3001 - acc: 0.9200 - val_loss: 0.5787 - val_acc: 0.8109\n",
      "iteration 3 out of 8\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.2786 - acc: 0.9300 - val_loss: 0.5419 - val_acc: 0.8246\n",
      "Epoch 2/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.2889 - acc: 0.9200 - val_loss: 0.5544 - val_acc: 0.8232\n",
      "Epoch 3/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.2757 - acc: 0.9220 - val_loss: 0.5524 - val_acc: 0.8184\n",
      "Epoch 4/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2665 - acc: 0.9300 - val_loss: 0.5444 - val_acc: 0.8236\n",
      "Epoch 5/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2695 - acc: 0.9280 - val_loss: 0.5490 - val_acc: 0.8250\n",
      "Epoch 6/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2762 - acc: 0.9160 - val_loss: 0.5711 - val_acc: 0.8110\n",
      "Epoch 7/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2579 - acc: 0.9240 - val_loss: 0.5467 - val_acc: 0.8223\n",
      "Epoch 8/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2452 - acc: 0.9380 - val_loss: 0.5516 - val_acc: 0.8214\n",
      "Epoch 9/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2466 - acc: 0.9320 - val_loss: 0.5258 - val_acc: 0.8311\n",
      "Epoch 10/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.2347 - acc: 0.9460 - val_loss: 0.5380 - val_acc: 0.8294\n",
      "Epoch 11/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2322 - acc: 0.9360 - val_loss: 0.5429 - val_acc: 0.8275\n",
      "Epoch 12/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2304 - acc: 0.9400 - val_loss: 0.5361 - val_acc: 0.8321\n",
      "Epoch 13/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.2245 - acc: 0.9400 - val_loss: 0.6149 - val_acc: 0.7966\n",
      "Epoch 14/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2631 - acc: 0.9200 - val_loss: 0.5495 - val_acc: 0.8286\n",
      "Epoch 15/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2224 - acc: 0.9420 - val_loss: 0.5583 - val_acc: 0.8242\n",
      "iteration 4 out of 8\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2154 - acc: 0.9400 - val_loss: 0.5355 - val_acc: 0.8312\n",
      "Epoch 2/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.2131 - acc: 0.9440 - val_loss: 0.5553 - val_acc: 0.8234\n",
      "Epoch 3/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2159 - acc: 0.9440 - val_loss: 0.5520 - val_acc: 0.8260\n",
      "Epoch 4/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2219 - acc: 0.9320 - val_loss: 0.6317 - val_acc: 0.7986\n",
      "Epoch 5/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2163 - acc: 0.9380 - val_loss: 0.5658 - val_acc: 0.8242\n",
      "Epoch 6/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.2106 - acc: 0.9440 - val_loss: 0.5489 - val_acc: 0.8293\n",
      "Epoch 7/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1938 - acc: 0.9460 - val_loss: 0.5451 - val_acc: 0.8307\n",
      "Epoch 8/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.1869 - acc: 0.9440 - val_loss: 0.5626 - val_acc: 0.8245\n",
      "Epoch 9/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1900 - acc: 0.9420 - val_loss: 0.5407 - val_acc: 0.8351\n",
      "Epoch 10/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1751 - acc: 0.9500 - val_loss: 0.5358 - val_acc: 0.8345\n",
      "Epoch 11/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.1848 - acc: 0.9520 - val_loss: 0.5546 - val_acc: 0.8312\n",
      "Epoch 12/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.1822 - acc: 0.9480 - val_loss: 0.5587 - val_acc: 0.8271\n",
      "Epoch 13/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1825 - acc: 0.9380 - val_loss: 0.5403 - val_acc: 0.8347\n",
      "Epoch 14/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1695 - acc: 0.9540 - val_loss: 0.5266 - val_acc: 0.8385\n",
      "Epoch 15/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1665 - acc: 0.9480 - val_loss: 0.5395 - val_acc: 0.8401\n",
      "iteration 5 out of 8\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1637 - acc: 0.9560 - val_loss: 0.5250 - val_acc: 0.8414\n",
      "Epoch 2/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1619 - acc: 0.9540 - val_loss: 0.5398 - val_acc: 0.8402\n",
      "Epoch 3/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1540 - acc: 0.9520 - val_loss: 0.5658 - val_acc: 0.8326\n",
      "Epoch 4/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1485 - acc: 0.9620 - val_loss: 0.5467 - val_acc: 0.8374\n",
      "Epoch 5/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1437 - acc: 0.9640 - val_loss: 0.5274 - val_acc: 0.8412\n",
      "Epoch 6/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1440 - acc: 0.9580 - val_loss: 0.5421 - val_acc: 0.8395\n",
      "Epoch 7/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.1332 - acc: 0.9680 - val_loss: 0.5558 - val_acc: 0.8353\n",
      "Epoch 8/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1417 - acc: 0.9660 - val_loss: 0.5526 - val_acc: 0.8374\n",
      "Epoch 9/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1328 - acc: 0.9640 - val_loss: 0.5491 - val_acc: 0.8406\n",
      "Epoch 10/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1352 - acc: 0.9600 - val_loss: 0.5727 - val_acc: 0.8347\n",
      "Epoch 11/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1281 - acc: 0.9620 - val_loss: 0.5440 - val_acc: 0.8392\n",
      "Epoch 12/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.1324 - acc: 0.9660 - val_loss: 0.5604 - val_acc: 0.8396\n",
      "Epoch 13/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.1345 - acc: 0.9540 - val_loss: 0.5664 - val_acc: 0.8299\n",
      "Epoch 14/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1353 - acc: 0.9560 - val_loss: 0.5397 - val_acc: 0.8371\n",
      "Epoch 15/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1401 - acc: 0.9600 - val_loss: 0.6440 - val_acc: 0.8084\n",
      "iteration 6 out of 8\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.1274 - acc: 0.9580 - val_loss: 0.5395 - val_acc: 0.8406\n",
      "Epoch 2/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1268 - acc: 0.9600 - val_loss: 0.5369 - val_acc: 0.8433\n",
      "Epoch 3/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1111 - acc: 0.9680 - val_loss: 0.5444 - val_acc: 0.8373\n",
      "Epoch 4/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1145 - acc: 0.9800 - val_loss: 0.5653 - val_acc: 0.8318\n",
      "Epoch 5/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1123 - acc: 0.9600 - val_loss: 0.5597 - val_acc: 0.8411\n",
      "Epoch 6/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1222 - acc: 0.9640 - val_loss: 0.5431 - val_acc: 0.8419\n",
      "Epoch 7/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1244 - acc: 0.9640 - val_loss: 0.5502 - val_acc: 0.8438\n",
      "Epoch 8/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1132 - acc: 0.9700 - val_loss: 0.5683 - val_acc: 0.8353\n",
      "Epoch 9/15\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.1065 - acc: 0.9720 - val_loss: 0.5770 - val_acc: 0.8360\n",
      "Epoch 10/15\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.0980 - acc: 0.9820 - val_loss: 0.5826 - val_acc: 0.8368\n",
      "Epoch 11/15\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.1198 - acc: 0.9640 - val_loss: 0.5896 - val_acc: 0.8306\n",
      "Epoch 12/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1029 - acc: 0.9740 - val_loss: 0.5947 - val_acc: 0.8355\n",
      "Epoch 13/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1062 - acc: 0.9680 - val_loss: 0.5467 - val_acc: 0.8479\n",
      "Epoch 14/15\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.0862 - acc: 0.9860 - val_loss: 0.6034 - val_acc: 0.8279\n",
      "Epoch 15/15\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.1001 - acc: 0.9720 - val_loss: 0.5804 - val_acc: 0.8394\n",
      "iteration 7 out of 8\n",
      "Train on 500 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.1182 - acc: 0.9660 - val_loss: 0.5550 - val_acc: 0.8453\n",
      "Epoch 2/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.0839 - acc: 0.9840 - val_loss: 0.5801 - val_acc: 0.8390\n",
      "Epoch 3/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.0903 - acc: 0.9780 - val_loss: 0.5975 - val_acc: 0.8383\n",
      "Epoch 4/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.0833 - acc: 0.9760 - val_loss: 0.5836 - val_acc: 0.8441\n",
      "Epoch 5/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.1018 - acc: 0.9680 - val_loss: 0.5884 - val_acc: 0.8405\n",
      "Epoch 6/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.0852 - acc: 0.9820 - val_loss: 0.5714 - val_acc: 0.8473\n",
      "Epoch 7/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.0798 - acc: 0.9800 - val_loss: 0.5636 - val_acc: 0.8465\n",
      "Epoch 8/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.0732 - acc: 0.9880 - val_loss: 0.5793 - val_acc: 0.8424\n",
      "Epoch 9/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.0804 - acc: 0.9800 - val_loss: 0.5827 - val_acc: 0.8403\n",
      "Epoch 10/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.0768 - acc: 0.9820 - val_loss: 0.5730 - val_acc: 0.8434\n",
      "Epoch 11/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.0778 - acc: 0.9840 - val_loss: 0.5729 - val_acc: 0.8446\n",
      "Epoch 12/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.0812 - acc: 0.9780 - val_loss: 0.6303 - val_acc: 0.8273\n",
      "Epoch 13/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.0773 - acc: 0.9860 - val_loss: 0.5596 - val_acc: 0.8471\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 6s 13ms/step - loss: 0.0729 - acc: 0.9860 - val_loss: 0.5697 - val_acc: 0.8459\n",
      "Epoch 15/15\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.0699 - acc: 0.9840 - val_loss: 0.5861 - val_acc: 0.8405\n",
      "iteration 8 out of 8\n"
     ]
    }
   ],
   "source": [
    "total_iteration=8\n",
    "results_noise_df_sgd_small_dataset=train_and_test(model_noise_sgd_small_dataset\\\n",
    "                                          ,total_iteration,x_test,y_test,x_train,y_train,epoces_per_step,add_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>add_noise</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.5886</td>\n",
       "      <td>1.329578</td>\n",
       "      <td>1.485861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>0.447785</td>\n",
       "      <td>0.676784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>True</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.8109</td>\n",
       "      <td>0.285252</td>\n",
       "      <td>0.578741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>True</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.8242</td>\n",
       "      <td>0.217201</td>\n",
       "      <td>0.558299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>True</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.8401</td>\n",
       "      <td>0.160263</td>\n",
       "      <td>0.539524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.8084</td>\n",
       "      <td>0.161015</td>\n",
       "      <td>0.644017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>105</td>\n",
       "      <td>True</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.8394</td>\n",
       "      <td>0.095672</td>\n",
       "      <td>0.580410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>120</td>\n",
       "      <td>True</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.8405</td>\n",
       "      <td>0.068617</td>\n",
       "      <td>0.586083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epochs  add_noise  train_accuracy  test_accuracy  train_loss  test_loss\n",
       "0      15       True           0.684         0.5886    1.329578   1.485861\n",
       "1      30       True           0.890         0.7900    0.447785   0.676784\n",
       "2      45       True           0.918         0.8109    0.285252   0.578741\n",
       "3      60       True           0.938         0.8242    0.217201   0.558299\n",
       "4      75       True           0.958         0.8401    0.160263   0.539524\n",
       "5      90       True           0.946         0.8084    0.161015   0.644017\n",
       "6     105       True           0.968         0.8394    0.095672   0.580410\n",
       "7     120       True           0.988         0.8405    0.068617   0.586083"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_noise_df_sgd_small_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " we can see that in this case modern methods works faster and better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion:\n",
    "The proposed method seems to work however it perform better job then std modern methods. This is the same result obtained by the relevant article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
